<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.7.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Li Wang">

  
  
  
    
  
  <meta name="description" content="Brief summary for understanding activation functions in NN">

  
  <link rel="alternate" hreflang="en-us" href="https://Alibabade.github.io/post/activation_functions_in_dl/">

  


  
  
  
  <meta name="theme-color" content="#dc7633">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CLora:400,700%7CEB Garamond%7CRoboto+Mono%7CRoboto:400,400italic,700&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://Alibabade.github.io/post/activation_functions_in_dl/">

  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Li Wang">
  <meta property="og:url" content="https://Alibabade.github.io/post/activation_functions_in_dl/">
  <meta property="og:title" content="Activation_functions_in_dl | Li Wang">
  <meta property="og:description" content="Brief summary for understanding activation functions in NN"><meta property="og:image" content="https://Alibabade.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png">
  <meta property="twitter:image" content="https://Alibabade.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2019-12-24T21:15:41&#43;00:00">
    
    <meta property="article:modified_time" content="2020-01-13T22:33:10&#43;00:00">
  

  


    






  






<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Alibabade.github.io/post/activation_functions_in_dl/"
  },
  "headline": "Activation_functions_in_dl",
  
  "datePublished": "2019-12-24T21:15:41Z",
  "dateModified": "2020-01-13T22:33:10Z",
  
  "author": {
    "@type": "Person",
    "name": "Li Wang"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Li Wang",
    "logo": {
      "@type": "ImageObject",
      "url": "img/https://Alibabade.github.io/"
    }
  },
  "description": "Brief summary for understanding activation functions in NN"
}
</script>

  

  


  


  





  <title>Activation_functions_in_dl | Li Wang</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Li Wang</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Li Wang</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured"><span>Publications</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Activation_functions_in_dl</h1>

  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/admin/">Li Wang</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
          Last updated on
      
    
    Jan 13, 2020
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    5 min read
  </span>
  

  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/categories/computer-vision/">Computer Vision</a>, <a href="/categories/dl/">DL</a></span>
  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      <h2 id="activation-functions">Activation functions</h2>
<h3 id="description">Description</h3>
<p>Activation functions works like an on-off button that determines whether the output of a neuron or what information should be passed to next layer. In biology, it works like synaptic in brain which decides what information it passes from one neuron cell to next one. There are several activation functions widely used in neural networks.</p>
<h3 id="binary-function-step-function">Binary function (step function)</h3>
<p>In one word, the output of binary function is 1 or 0 which is based on whether the input is greater or lower than a threshold. In math, it looks like this:
f(x) = {1, if x &gt; T; 0, otherwise}.</p>
<p>Cons: it does not allow multiple outputs, and it can not support to classify inputs to one of categories.</p>
<h3 id="linear-function">Linear function</h3>
<p>f(x) = $cx$. <strong>Cons:</strong> 1. the deviation of linear function is a constant, which does not help for backpropagation as the deviation is not correlated to its inputs, in another word, it can not distinguih what weights or parameters help to learn the task; 2. linear function makes the entire multiple neural network into one linear layer (as the combination of linear functions is still a linear function), which becomes a simple regression model. It can not handle complex tasks by varying parameters of inputs.</p>
<h3 id="non-linear-functions">Non-linear functions</h3>
<p>Non-linear functions address the problems by two aspects:</p>
<ol>
<li>The deviation of non-liear function is a function correlated to its inputs, which contributes the backpropagation to learn how to update weights for high accurancy.</li>
<li>Non-linear functions form the layers with hidden neurons into a deep neural network which is capable of predicting for complicated tasks by learning from complex datasets.</li>
</ol>
<p>There are several popular activation functions used in modern deep neural networks.</p>
<h3 id="sigmoidlogistic-regression">Sigmoid/Logistic Regression</h3>



  











<figure>


  <a data-fancybox="" href="/img/sigmoid.png" data-caption="Fig 1. Sigmoid Visualization">
<img data-src="/img/sigmoid.png" class="lazyload" alt="" ></a>


  
  
  <figcaption>
    Fig 1. Sigmoid Visualization
  </figcaption>


</figure>

<p>Equation: $$Sigmoid(x) = \frac{1}{1+e^{-x}}$$
Derivative (with respect to $x$): $$Sigmoid^{'}(x) = Sigmoid(x)(1-Sigmoid(x))$$
<strong>Pros:</strong></p>
<ol>
<li><strong>smooth gradient</strong>, no jumping output values compared to binary function.</li>
<li><strong>output value lies between 0 and 1</strong>, normalizing output of each neuron.</li>
<li><strong>right choice for probability prediction</strong>, the probability of anything exists only between 0 and 1.</li>
</ol>
<p><strong>Cons:</strong></p>
<ol>
<li><strong>vanishing gradient</strong>, the gradient barely changes when $x&gt;2$ or $x&lt;-2$.</li>
<li><strong>computationally expensive.</strong></li>
<li><strong>non zero centered outputs.</strong> The outputs after applying sigmoid are always positive, during gradient descent, the gradients on weights in backpropagation will always be positive or negative, which means the gradient updates go too far in different directions, and makes the optimization harder.</li>
</ol>
<h3 id="softmax">Softmax</h3>
<p>$$Softmax(x_i)= \frac{x_i}{\Sigma_{j=1}^{n}{x_j}}$$</p>
<p><strong>Pros:</strong> capable of handling multiple classification and the sum of predicted probabilities is 1. <strong>Cons:</strong> only used for output layer.</p>
<p><strong>Softmax is more suitable for multiple classification case when the predicted class must and only be one of categories. k-sigmoid/LR can be used to classify such multi-class problem that the predicted class could be multiple.</strong></p>
<h3 id="tanh">Tanh</h3>
<p>Equation: $$tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$$
Derivative (with respect to $x$): $$tanh^{'}(x) = 1 -tanh(x)^2$$</p>
<p><strong>Pros:</strong></p>
<ol>
<li>zero centered. make it easier to model inputs that have strongly positive, strongly negative, and natural values.</li>
<li>similar to sigmoid</li>
</ol>
<p><strong>Cons:</strong></p>
<ol>
<li><strong>vanishing gradient</strong></li>
<li><strong>computationally expensive</strong> as it includes division and exponential operation.</li>
</ol>
<h3 id="vanishing-gradient">Vanishing gradient</h3>
<p>Vanishing gradient means that the values of weights and biases are barely change along with the training.</p>
<h3 id="exploding-gradient">Exploding gradient</h3>
<p>Gradient explosion means that the values of weights and biases are increasing rapidly along with the training.</p>
<h3 id="relu">ReLU</h3>
<p>


  











<figure>


  <a data-fancybox="" href="/img/relu.png" data-caption="Fig 2. ReLU Visualization">
<img data-src="/img/relu.png" class="lazyload" alt="" ></a>


  
  
  <figcaption>
    Fig 2. ReLU Visualization
  </figcaption>


</figure>

Equation: $$ReLU(x) = max(0, x)$$
Derivative (with respect to $x$):
\begin{equation}
ReLU^{'}(x) = \begin{cases}
0, &amp;x \leqslant 0; \newline
1, &amp; x &gt; 0
\end{cases}
\end{equation}
<strong>Pros:</strong></p>
<ol>
<li>computationally efficient</li>
<li>non-linear</li>
</ol>
<p><strong>Why ReLU performs better in modern NNs?</strong> The answer is not so sure right now, but its propeties like <strong>non-saturation gradient</strong> and <strong>computionally efficient</strong> indeed lead to fast convergence. Additionally, its property <strong>sparsing the network</strong> also improves the modeling preformance. The <strong>non-zero centered issue</strong> can be tackled by other regularization techniques like <strong>Batch Normalization</strong> which produces a stable distribution for ReLU.</p>
<p><strong>Cons:</strong></p>
<ol>
<li>Dying ReLU problem. The backpropagation won&rsquo;t work when inputs approach zero or negative.
However, to some extent, dying ReLU problem makes input values sparse which is helpful for neural network to learn more important values and perform better.</li>
<li>Non differentiable at zero.</li>
<li>Non zero centered.</li>
<li>Don&rsquo;t avoid gradient explode</li>
</ol>
<h3 id="elu">ELU</h3>
<p>


  











<figure>


  <a data-fancybox="" href="/img/elu.png" data-caption="Fig 3. ELU Visualization">
<img data-src="/img/elu.png" class="lazyload" alt="" ></a>


  
  
  <figcaption>
    Fig 3. ELU Visualization
  </figcaption>


</figure>

Equation:
\begin{equation}
ELU(x) = \begin{cases}
\alpha (e^x-1), &amp; x \leqslant 0 \newline
x, &amp;x &gt; 0    <br>
\end{cases}
\end{equation}</p>
<p>Derivative:
\begin{equation}
ELU^{'}(x) = \begin{cases}
ELU(x) + \alpha, &amp; x \leqslant 0 \newline
1, &amp; x &gt; 0
\end{cases}
\end{equation}</p>
<p><strong>Pros:</strong></p>
<ol>
<li>prevent dying ReLU problem.</li>
<li>gradient works when input values are negative.</li>
<li>non-linear, gradient is not zero.</li>
</ol>
<p><strong>Cons:</strong></p>
<ol>
<li>don&rsquo;t avoid gradient explode.</li>
<li>not computationally efficient.</li>
<li>$\alpha$ is not learnt by neural networks.</li>
</ol>
<h3 id="leaky-relu">Leaky ReLU</h3>
<p>


  











<figure>


  <a data-fancybox="" href="/img/lrelu.png" data-caption="Fig 4. LReLU Visualization ($\alpha=0.1$)">
<img data-src="/img/lrelu.png" class="lazyload" alt="" ></a>


  
  
  <figcaption>
    Fig 4. LReLU Visualization ($\alpha=0.1$)
  </figcaption>


</figure>

Equation:
\begin{equation}
LReLU(x) = \begin{cases}
\alpha x,  &amp;x \leqslant 0 \newline
x, &amp;x &gt; 0
\end{cases}
\end{equation}</p>
<p>Derviative:
\begin{equation}
LReLU^{'}(x) = \begin{cases}
\alpha, &amp;x \leqslant 0 \newline
1, &amp;x &gt; 0
\end{cases}
\end{equation}</p>
<p><strong>Pros:</strong></p>
<ol>
<li>prevent Dying ReLU problem</li>
<li>computationally efficient</li>
<li>non-linear</li>
</ol>
<p><strong>Cons:</strong></p>
<ol>
<li>don&rsquo;t avoid gradient explode</li>
<li>Non consistent results for negative input values.</li>
<li>non-zero centered</li>
<li>non differentiable at Zeros</li>
</ol>
<h3 id="selu">SELU</h3>
<p>


  











<figure>


  <a data-fancybox="" href="/img/selu.png" data-caption="Fig 5. SELU Visualization">
<img data-src="/img/selu.png" class="lazyload" alt="" ></a>


  
  
  <figcaption>
    Fig 5. SELU Visualization
  </figcaption>


</figure>

Equation:
\begin{equation}
SELU(x) = \lambda \begin{cases}
\alpha e^x-\alpha, &amp; x \leqslant 0 \newline
x, &amp; x &gt; 0
\end{cases}
\end{equation}</p>
<p>Derivative:
\begin{equation}
SELU^{'}(x) = \lambda \begin{cases}
\alpha e^x, &amp; x \leqslant 0 \newline
1, &amp; x &gt; 0
\end{cases}
\end{equation}
where $\alpha \approx 1.6732632423543772848170429916717$ and $\lambda \approx 1.0507009873554804934193349852946$.</p>
<p><strong>Pros:</strong></p>
<ol>
<li>Internal normalization, which means faster convergence.</li>
<li>Preventing vanishing gradient and exploding gradient.</li>
</ol>
<p><strong>Cons:</strong>
Need more applications to prove its performance on CNNs and RNNs.</p>
<h3 id="gelu">GELU</h3>
<p>


  











<figure>


  <a data-fancybox="" href="/img/gelu.png" data-caption="Fig 6. GELU Visualization">
<img data-src="/img/gelu.png" class="lazyload" alt="" ></a>


  
  
  <figcaption>
    Fig 6. GELU Visualization
  </figcaption>


</figure>

Equation:
\begin{equation}
GELU(x) = 0.5x(1 + tanh(\sqrt{\frac{2}{\pi}} (x + 0.044715x^3)))
\end{equation}</p>
<p><strong>Pros:</strong></p>
<ol>
<li>Best performance in NLP, especially BERT and GPT-2</li>
<li>Avoid vanishing gradient</li>
</ol>
<p><strong>Cons:</strong>
Need more applications to prove its performance.</p>
<h3 id="reference">Reference</h3>
<ol>
<li><a href="https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/">https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/</a></li>
<li><a href="https://www.jianshu.com/p/6db999961393">https://www.jianshu.com/p/6db999961393</a></li>
<li><a href="https://towardsdatascience.com/activation-functions-b63185778794">https://towardsdatascience.com/activation-functions-b63185778794</a></li>
<li><a href="https://datascience.stackexchange.com/questions/23493/why-relu-is-better-than-the-other-activation-functions">https://datascience.stackexchange.com/questions/23493/why-relu-is-better-than-the-other-activation-functions</a></li>
</ol>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/academic/">Academic</a>
  
  <a class="badge badge-light" href="/tags/activation-functions-in-dl/">Activation functions in DL</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://Alibabade.github.io/post/activation_functions_in_dl/&amp;text=Activation_functions_in_dl" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://Alibabade.github.io/post/activation_functions_in_dl/&amp;t=Activation_functions_in_dl" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Activation_functions_in_dl&amp;body=https://Alibabade.github.io/post/activation_functions_in_dl/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://Alibabade.github.io/post/activation_functions_in_dl/&amp;title=Activation_functions_in_dl" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Activation_functions_in_dl%20https://Alibabade.github.io/post/activation_functions_in_dl/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://Alibabade.github.io/post/activation_functions_in_dl/&amp;title=Activation_functions_in_dl" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
  
    
  
  






  
  
  
    
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_hu8c1967adf340de7ae400ce95dd873c2d_1186948_250x250_fill_lanczos_center_2.png" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://Alibabade.github.io/">Li Wang</a></h5>
      <h6 class="card-subtitle">PhD</h6>
      <p class="card-text">My research focuses on image/video based neural style transfer.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/liwang1991@outlook.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.facebook.com/profile.php?id=100013393752495" target="_blank" rel="noopener">
        <i class="fab fa-facebook"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.co.uk/citations?user=KKNBDWQAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/Alibabade" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://drive.google.com/file/d/1gk3Kai4j19FPTplrsQjSpS2qOYmfwb5G/view?usp=sharing" target="_blank" rel="noopener">
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>









  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/post/basic_understanding_dl/">Discrete_specific_techniques_dl</a></li>
      
      <li><a href="/post/normalizaion_in_dl/">Normalization_in_DL</a></li>
      
    </ul>
  </div>
  



  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.4.3/mermaid.min.js" integrity="" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
      

    

    
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.a0d331bcd05dbe8b31e244f796710f08.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
